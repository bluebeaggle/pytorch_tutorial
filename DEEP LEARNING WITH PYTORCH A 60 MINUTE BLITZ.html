<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>DEEP LEARNING WITH PYTORCH : A 60 MINUTE BLITZ</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1baea6dd-bc9e-463a-ba0a-86e49c746715" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">ğŸ¦´</span></div><h1 class="page-title"><strong>DEEP LEARNING WITH PYTORCH : A 60 MINUTE BLITZ</strong></h1></header><div class="page-body"><p id="6dea95d8-cdd8-4db8-8535-2258370954fe" class="">
</p><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3">Tensor</summary><div class="indented"><ul id="9c6394cb-b546-47c8-bc1e-9b206824a496" class="bulleted-list"><li style="list-style-type:disc">Numpyì˜ ndarray í˜¹ì€ Matrix(í–‰ë ¬)ê³¼ ìœ ì‚¬í•œ íŠ¹ìˆ˜ ìë£Œêµ¬ì¡°</li></ul><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Tensor ì´ˆê¸°í™” í•˜ê¸°</summary><div class="indented"><pre id="559b4c8c-1088-4355-ae9d-b3550598334b" class="code"><code>import torch
import numpy as np

# No.1 : ë°ì´í„°ë¡œë¶€í„° ì§ì ‘(directly) ìƒì„±í•˜ê¸°
data = [[1,2],[3,4]]
x_data = torch.tensor(data)

# No.2 : Numpy ë°°ì—´ë¶€í„° ìƒì„±í•˜ê¸°
np.array = np.array([data])
x_np = torch.from_numpy(np_array)

# No.3 : ë‹¤ë¥¸ í…ì„œë¡œë¶€í„° ìƒì„±í•˜ê¸°
# ì§ì ‘ Override í•˜ì§€ì•Šìœ¼ë©´, shapeê³¼ datatypeì´ ìœ ì§€ë¨
x_ones = torch.ones_like(x_data)                     # x_dataì˜ ì†ì„±ì„ ìœ ì§€í•¨
print(f&#x27;Ones Tensor : ]n {x_ones} \n&#x27;)

x_rand = torch.rand_like(x_data, dtype=torch.float)  # x_dataì˜ ì†ì„±ì„ ë®ì–´ì”€
print(f&#x27;Random Tensor : ]n {x_rand} \n&#x27;)

# No.4 : ë¬´ì‘ìœ„(Random) or ìƒìˆ˜(constant) ê°’ ì‚¬ìš©í•˜ê¸°
# shapeì€ í…ì„œì˜ ì°¨ì›(dimension)ì„ ë‚˜íƒ€ë‚´ëŠ” íŠœí”Œ

shape = (2,3,)
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)

print(f&quot;Random Tensor: \n {rand_tensor} \n&quot;)
print(f&quot;Ones Tensor: \n {ones_tensor} \n&quot;)
print(f&quot;Zeros Tensor: \n {zeros_tensor}&quot;)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Tensor ì†ì„±(Attribute)</summary><div class="indented"><p id="4c35cc61-c459-4950-80ad-12bf5c5f519b" class="">í…ì„œì˜ ëª¨ì–‘(shape), ìë£Œí˜•(datatype) ë° ì–´ëŠ ì¥ì¹˜ì— ì €ì¥ë˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„</p><pre id="8d18c187-8bca-4b25-96f0-8b691c069f59" class="code"><code>tensor = torch.rand(3,4)

print(f&quot;Shape of tensor: {tensor.shape}&quot;)
print(f&quot;Datatype of tensor: {tensor.dtype}&quot;)
print(f&quot;Device tensor is stored on: {tensor.device}&quot;)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Tensor ì—°ì‚°(Operation)</summary><div class="indented"><p id="f98c9a4c-767b-4a08-a443-fc73dd8c8b44" class="">ì „ì¹˜(Transposing), ì¸ë±ì‹±(Indexing), ìŠ¬ë¼ì´ì‹±(Slicing)
ìˆ˜í•™ê³„ì‚°, ì„ í˜•ëŒ€ìˆ˜, ì„ì˜ ìƒ˜í”Œë§(Random sampling)ë“±, 100ê°€ì§€ ì´ìƒ ì—°ì‚° ê°€ëŠ¥í•˜ë©° <mark class="highlight-red"><a href="https://pytorch.org/docs/stable/torch.html">ì—¬ê¸°</a></mark>ì„œ í™•ì¸ ê°€ëŠ¥</p><pre id="17559eb5-370e-4532-b027-310302cf6c2c" class="code"><code># GPU ì‚¬ìš© ê°€ëŠ¥í•  ì‹œ GPU ì‚¬ìš©í•˜ê¸°

# GPUê°€ ì¡´ì¬í•˜ë©´ í…ì„œë¥¼ ì´ë™í•©ë‹ˆë‹¤
if torch.cuda.is_available():
  tensor = tensor.to(&#x27;cuda&#x27;)
  print(f&quot;Device tensor is stored on: {tensor.device}&quot;)


#  Numpyì‹ í‘œì¤€ ì¸ë±ì‹±ê³¼ ìŠ¬ë¼ì´ì‹±
tensor = torch.ones(4,4)
tensor[:,1] = 0
print(tensor)

# tensor í•©ì¹˜ê¸°
# torch stackì€ torch.catê³¼ ë¯¸ë¬˜í•˜ê²Œ ë‹¤ë¦„
t1 = torch.cat([tensor, tensor, tensor], dim=1)
print(t1)

t2 = torch.stack([tensor, tensor, tensor], dim=1)
print(t2)

# tesnor ê³±í•˜ê¸°
# ìš”ì†Œ ë³„(element-wise product) ê³„ì‚°
tesor_mul1 = tensor.mul(tensor)
print(f&quot;tensor.mul(tensor) \n {tesor_mul1} \n&quot;)
tensor_mul2 = tensor*tensor
print(f&quot;tensor * tensor \n {tensor_mul2}&quot;)

# tensor ë°”ê¿”ì¹˜ê¸° (in-place)
# _ ì ‘ë¯¸ì‚¬ë¥¼ ê°–ëŠ” ì—°ì‚°ë“¤ì€ ë°”ê¿”ì¹˜ê¸°(in-place) ì—°ì‚°
# ë©”ëª¨ë¦¬ë¥¼ ì¼ë¶€ ì ˆì•½í•˜ì§€ë§Œ, ì›ë³¸dataê°€ ì‚­ì œë˜ì–´, ë„í•¨ìˆ˜ ê³„ì‚°ì— ë¬¸ì œ ë°œìƒ í•  ìˆ˜ ìˆì–´, ì‚¬ìš© ê¶Œì¥x
print(tensor, &quot;\n&quot;)
tensor.add_(5)
print(tensor)
</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Numpy ë³€í™˜ (Bridge)</summary><div class="indented"><p id="ca02bcc7-ae23-44c8-8f5c-41d1c65ddb6f" class="">CPU ìƒì˜ í…ì„œì™€ NumPy ë°°ì—´ì€ ë©”ëª¨ë¦¬ ê³µê°„ì„ ê³µìœ í•˜ê¸° ë•Œë¬¸ì—, í•˜ë‚˜ë¥¼ ë³€ê²½í•˜ë©´ ë‹¤ë¥¸ í•˜ë‚˜ë„ ë³€ê²½ë¨</p><pre id="98eed3fb-c34b-406e-95d4-3637667cbe4f" class="code"><code>t = torch.ones(5)
print(f&#x27;t = {t}&#x27;)
n = t.numpy()
print(f&#x27;n = {n}&#x27;)

t.add_(1)
print(f&#x27;t = {t}&#x27;)
print(f&#x27;n = {n}&#x27;)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Numpy â†’ Tensorë¡œ ë³€í™˜</summary><div class="indented"><pre id="01b4aa81-a2e8-4038-b11b-2f20f7dcf6cb" class="code"><code>n = np.ones(5)
t = torch.from_numpy(n)

# Numpyì˜ ë³€ê²½ ì‚¬í•­ì´ Tensorì—ë„ ë°˜ì˜ë¨
np.add(n, 1, out=n)
print(f&quot;t: {t}&quot;)
print(f&quot;n: {n}&quot;)
</code></pre></div></details></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3">torch.autograd</summary><div class="indented"><ul id="497c33df-f9ac-4459-a95b-e353f813dd35" class="bulleted-list"><li style="list-style-type:disc"><code>torch.autograd</code><strong>Â ëŠ” ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì„ ê³„ì‚°í•˜ëŠ” ì—”ì§„</strong></li></ul><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="ae9d517f-5bc6-4252-9e57-6b7ddae8b2d4"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%">ì‹ ê²½ë§ì˜ í•™ìŠµ ë°©ë²•
1. ìˆœì „íŒŒ (Forward Propagation)
 - ê°’ì„ ì¶”ì¸¡í•˜ê¸° ìœ„í•´ input dataë¥¼ ì…ë ¥
2. ì—­ì „íŒŒ (Backward Propagation)
 - ì¶”ì¸¡í•œ ê°’ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ì— ë¹„ë¡€í•˜ì—¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì ˆ
 - ì¶œë ¥ìœ¼ë¡œë¶€í„° ì—­ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ë©° í•¨ìˆ˜ ë§¤ê°œë³€ìˆ˜ì˜ ë¯¸ë¶„ê°’ì„ ìˆ˜ì§‘í•˜ê³ , ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•´ ìµœì í™” ì‹¤ì‹œ
 - ìì„¸í•œ <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">ì˜ìƒì€ ì°¸ì¡°</a></div></figure><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">ì‚¬ìš©ë²•</summary><div class="indented"><p id="6a749c69-c1da-4e29-b57e-ff45902b7102" class="">ì—¬ê¸°ì—ì„œëŠ”Â <code>torchvision</code>Â ì—ì„œ ë¯¸ë¦¬ í•™ìŠµëœ resnet18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. 3ì±„ë„ì§œë¦¬ ë†’ì´ì™€ ë„“ì´ê°€ 64ì¸ ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ í‘œí˜„í•˜ëŠ” ë¬´ì‘ìœ„ì˜ ë°ì´í„° í…ì„œë¥¼ ìƒì„±í•˜ê³ , ì´ì— ìƒì‘í•˜ëŠ”Â <code>label(ì •ë‹µ)</code>Â ì„ ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì˜ ì •ë‹µ(label)ì€ (1, 1000)ì˜ ëª¨ì–‘(shape)ì„ ê°–ìŠµë‹ˆë‹¤.</p><pre id="a26c97e5-20fc-4a5f-a6fd-74ac7e963bf4" class="code"><code>import torch
from torchvision.models import resnet18, ResNet18_Weights
model = resnet18(weights=ResNet18_Weights.DEFAULT)
data = torch.rand(1, 3, 64, 64)
labels = torch.rand(1, 1000)

# Forward Propagation
# Input dataë¥¼ layerì— í†µê³¼ì‹œì¼œ Predictionì„ ì–»ëŠ” ê³¼ì •
prediction = model(data)

# ì˜¤ì°¨(error, loss) ê³„ì‚°
# ì˜¤ì°¨ë¥¼ Backward Propagation ì‹¤ì‹œ
loss = (prediction - labels).sum()
loss.backward()    # ì—­ì „íŒŒ ì‹œì‘

# Optimizer ë¶ˆëŸ¬ì˜¤ê¸°
# í•™ìŠµë¥ (learning rate) 0.1ê³¼ ëª¨ë©¤í…€ 0.9ë¥¼ ê°€ì§„ SGD
optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)

# ê²½ì‚¬í•˜ê°•ë²• ì´ìš©
optim.step()
</code></pre><p id="8d413abc-5ca9-4423-965d-0f7695c2999d" class="">
</p></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">Autogradì—ì„œ ë¯¸ë¶„(Differentiation)</summary><div class="indented"><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3"><code>autograd</code>Â ê°€ ì–´ë–»ê²Œ <mark class="highlight-red">ë³€í™”ë„(gradient)ë¥¼ ìˆ˜ì§‘</mark>í•˜ëŠ”ì§€ ì‚´í´ë³´ê¸°</summary><div class="indented"><pre id="a312d43f-3f72-4efc-90cd-d8772cc3a3dd" class="code"><code>import torch

# requires_grad = audogradì˜ ëª¨ë“  ì—°ì‚°ì„ ì¶”ì í•¨
a = torch.tensor([2., 3.], requires_grad=True)
b = torch.tensor([6., 4.], requires_grad=True)

Q = 3*a**3 - b**2

# Q ì— ëŒ€í•´ì„œ .backward() ë¥¼ í˜¸ì¶œí•  ë•Œ
# autogradëŠ” ì´ëŸ¬í•œ ë³€í™”ë„ë“¤ì„ ê³„ì‚°í•˜ê³  ì´ë¥¼ ê° í…ì„œì˜ .grad ì†ì„±(attribute)ì— ì €ì¥
external_grad = torch.tensor([1., 1.])
Q.backward(gradient=external_grad)

#ë³€í™”ë„ëŠ” a.grad ì™€ b.grad ì— ì €ì¥
# ìˆ˜ì§‘ëœ ë³€í™”ë„ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
print(9*a**2 == a.grad)
print(-2*b == b.grad)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3">ì„ íƒì ìœ¼ë¡œ ì½ê¸° (Optional Reading)
- autogradë¥¼ ì‚¬ìš©í•œ ë²¡í„° ë¯¸ì ë¬¸(calculus)</summary><div class="indented"><p id="7cee7581-4f1b-45ba-90ff-39be8b8417b9" class="">ë²¡í„° í•¨ìˆ˜ <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>âƒ—</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>âƒ—</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">{\vec y } = f({\vec x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9084399999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.17994em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>ï»¿</span></span> ì—ì„œ <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>âƒ—</mo></mover></mrow><annotation encoding="application/x-tex">{\vec x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.714em;vertical-align:0em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.20772em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span>ì— ëŒ€í•œ <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>âƒ—</mo></mover></mrow><annotation encoding="application/x-tex">{\vec y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9084399999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.17994em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg width='0.471em' height='0.714em' style='width:0.471em' viewBox='0 0 471 714' preserveAspectRatio='xMinYMin'><path d='M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z'/></svg></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span></span></span></span><span>ï»¿</span></span>ì˜ ë³€í™”ë„ëŠ” ì•¼ì½”ë¹„ì•ˆ í–‰ë ¬ <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">J:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span></span><span>ï»¿</span></span> ì´ë‹¤</p><p id="aab013c4-dcb8-4ff4-824b-25da3d988148" class="">ì¼ë°˜ì ìœ¼ë¡œ,Â <code>torch.autograd</code>Â ëŠ” ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì„ ê³„ì‚°í•˜ëŠ” ì—”ì§„</p></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3"><strong>ì—°ì‚° ê·¸ë˜í”„(Computational Graph)</strong></summary><div class="indented"><p id="fb93a564-1d9c-4cd9-9f87-3044b8311589" class="">autogradëŠ” tensorì— ì‹¤í–‰ëœ ëª¨ë“  ì—°ì‚°ë“¤(ë° ì—°ì‚° ê²°ê³¼ê°€ ìƒˆë¡œìš´ í…ì„œì¸ ê²½ìš°ë„ í¬í•¨)ì˜ ê¸°ë¡ì„ Function ê°ì²´ë¡œ êµ¬ì„±ëœ ë°©í–¥ì„± ë¹„ìˆœí™˜ ê·¸ë˜í”„(DAG)ì— ì €ì¥í•¨.</p><p id="79a1fe6f-2198-44d9-bd4d-882c91bb21f4" class="">DAGì˜ ì(leaf)ì€ ì…ë ¥í…ì„œì´ê³ , ë¿Œë¦¬(root)ëŠ” ê²°ê³¼ í…ì„œì´ë©°, ë¿Œë¦¬ì—ì„œ ìê¹Œì§€ ì¶”ì í•˜ë©´ ì—°ì‡„ë²•ì¹™ (chain rule)ì— ë”°ë¼ ë³€í™”ë„ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆìŒ.</p><p id="92788538-1555-4613-bae7-495771ec5694" class="">
</p><ol type="1" id="fb0f20ce-cce6-4a63-8fe8-82de022abf07" class="numbered-list" start="1"><li>ìˆœì „íŒŒ ë‹¨ê³„ì—ì„œì˜ autogradì˜ ì‘ì—…<ol type="a" id="33c1a501-742b-4701-b255-6f383c83f5d9" class="numbered-list" start="1"><li>ìš”ì²­ëœ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ ê²°ê³¼ í…ì„œë¥¼ ê³„ì‚°</li></ol><ol type="a" id="be44f047-0c70-46e8-b485-672108393fec" class="numbered-list" start="2"><li>DAGì— ì—°ì‚°ì˜ ë³€í™”ë„ ê¸°ëŠ¥(gradient function)ì„ ìœ ì§€(maintain)</li></ol></li></ol><ol type="1" id="a37fb35c-cc03-4aa3-b091-ebc9ba3e4e69" class="numbered-list" start="2"><li>ì—­ì „íŒŒ ë‹¨ê³„ëŠ” DAGì˜ ë¿Œë¦¬ì—ì„œ .backward()ê°€ í˜¸ì¶œë ë•Œ ì‹œì‘.<ol type="a" id="1921a273-5445-4572-a4ab-5062ac0752dd" class="numbered-list" start="1"><li>ê° .grad_fn ìœ¼ë¡œë¶€í„° ë³€í™”ë„ ê³„ì‚°</li></ol><ol type="a" id="3b072467-3acd-491e-841f-51496d3f43f6" class="numbered-list" start="2"><li>ê° í…ì„œì˜ .grad ì†ì„±ì— ê³„ì‚° ê²°ê³¼ë¥¼ ìŒ“ê³ (accumulate)</li></ol><ol type="a" id="9d0f82a2-5d07-4b4b-8f4d-456e0a7a6702" class="numbered-list" start="3"><li>ì—°ì‡„ë²•ì¹™(chain rule)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì(leaf) í…ì„œë“¤ê¹Œì§€ ì „íŒŒ(propagation) ì‹¤ì‹œ</li></ol></li></ol></div></details><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3">DAGì—ì„œ ì œì™¸ í•˜ê¸°</summary><div class="indented"><p id="b135984b-cf7b-46fc-8f87-af180c2d36b8" class=""><strong><code>torch.autograd</code></strong><strong>Â ëŠ”Â </strong><strong><code>requires_grad</code></strong><strong>Â í”Œë˜ê·¸(flag)ê°€Â </strong><strong><code>True</code></strong><strong>Â ë¡œ ì„¤ì •ëœ ëª¨ë“  í…ì„œì— ëŒ€í•œ ì—°ì‚°ë“¤ì„ ì¶”ì í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë³€í™”ë„ê°€ í•„ìš”í•˜ì§€ ì•Šì€ í…ì„œë“¤ì— ëŒ€í•´ì„œëŠ” ì´ ì†ì„±ì„Â </strong><strong><code>False</code></strong><strong>Â ë¡œ ì„¤ì •í•˜ì—¬ DAG ë³€í™”ë„ ê³„ì‚°ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.</strong></p><p id="779e254a-4459-4984-add1-f9c95a0be47c" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="6bb2ede9-7526-4790-99d9-69dca1ea6352"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%">ì‹ ê²½ë§ì—ì„œ, ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ ì¼ë°˜ì ìœ¼ë¡œÂ <strong>ê³ ì •ëœ ë§¤ê°œë³€ìˆ˜(frozen parameter)</strong>Â ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. 
ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ë¯¸ë¦¬ ì•Œê³  ìˆìœ¼ë©´, 
ì‹ ê²½ë§ ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ã€Šê³ ì •(freeze)ã€‹í•˜ëŠ” ê²ƒì´ ìœ ìš©í•¨.
(ì´ë ‡ê²Œ í•˜ë©´ autograd ì—°ì‚°ëŸ‰ì„ ì¤„ì„ìœ¼ë¡œì¨ ì„±ëŠ¥ ìƒì˜ ì´ë“ì„ ì œê³µí•©ë‹ˆë‹¤.)

DAGì—ì„œ ì œì™¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•œ ë˜ ë‹¤ë¥¸ ì¼ë°˜ì ì¸ ì‚¬ë¡€(usecase)ëŠ”Â <mark class="highlight-red"><strong><a href="https://tutorials.pytorch.kr/beginner/finetuning_torchvision_models_tutorial.html">ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •</a></strong></mark>Â í•˜ëŠ” ê²½ìš°ì…ë‹ˆë‹¤.</div></figure><pre id="498d8ecc-f2f0-4b23-9a7c-89a420cb9a2f" class="code"><code># ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì˜ ë¯¸ì„¸ì¡°ì •

from torch import nn, optim

model = resnet18(weights=ResNet18_Weights.DEFAULT)

# ì‹ ê²½ë§ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •í•©ë‹ˆë‹¤
for param in model.parameters():
    param.requires_grad = False

# 10ê°œì˜ ì •ë‹µ(label)ì„ ê°–ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•˜ëŠ” ìƒí™©ì„ ê°€ì •
# resnetì—ì„œ ë¶„ë¥˜ê¸°(classifier)ëŠ” ë§ˆì§€ë§‰ ì„ í˜• ê³„ì¸µ(linear layer)ì¸ model.fc
# ì´ë¥¼ ìƒˆë¡œìš´ ë¶„ë¥˜ê¸°ë¡œ ë™ì‘í•  (ê³ ì •ë˜ì§€ ì•Šì€) ìƒˆë¡œìš´ ì„ í˜• ê³„ì¸µìœ¼ë¡œ ê°„ë‹¨íˆ ëŒ€ì²´
model.fc = nn.Linear(512, 10)

# ì´ì œ model.fc ë¥¼ ì œì™¸í•œ ëª¨ë¸ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë“¤ì´ ê³ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
# ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ìœ ì¼í•œ ë§¤ê°œë³€ìˆ˜ëŠ” model.fc ì˜ ê°€ì¤‘ì¹˜(weight)ì™€ í¸í–¥(bias)ë¿

# ë¶„ë¥˜ê¸°ë§Œ ìµœì í™”í•©ë‹ˆë‹¤.
optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)</code></pre></div></details></div></details></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3">Neural Networks</summary><div class="indented"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2906145d-7844-4256-8d86-c6b388bb7b70"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%"><strong>ì‹ ê²½ë§ì€Â </strong><code>torch.nn</code><strong>Â íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±</strong><p id="09eb757f-632e-4f3e-804a-aa78fdd1728b" class=""><code>nn</code><strong>Â ì€ ëª¨ë¸ì„ ì •ì˜í•˜ê³  ë¯¸ë¶„í•˜ëŠ”ë°Â </strong><code>autograd</code><strong>Â ë¥¼ ì‚¬ìš©</strong></p><p id="dd1c3691-59a0-4b30-abb0-76debaa12d49" class=""><code>nn.Module</code><strong>Â ì€ ê³„ì¸µ(layer)ê³¼Â </strong><code>output</code><strong>Â ì„ ë°˜í™˜í•˜ëŠ”Â </strong><code>forward(input)</code><strong>Â ë©”ì„œë“œë¥¼ í¬í•¨</strong></p></div></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="3298b736-b798-47fe-b630-e666c0c9f4e2"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%"><code>torch.nn</code><strong>Â ì€ ë¯¸ë‹ˆë°°ì¹˜(mini-batch)ë§Œ ì§€ì›
</strong><code>torch.nn</code><strong>Â íŒ¨í‚¤ì§€ ì „ì²´ëŠ” í•˜ë‚˜ì˜ ìƒ˜í”Œì´ ì•„ë‹Œ, ìƒ˜í”Œë“¤ì˜ ë¯¸ë‹ˆë°°ì¹˜ë§Œì„ ì…ë ¥ ë°›ìŒ</strong></div></figure><p id="b384d274-2638-4e7e-85ad-fe06e72014e6" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="e02f9154-6d71-4b5d-ab2b-8f4db3511e00"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%">ì‹ ê²½ë§ì˜ ì¼ë°˜ì ì¸ í•™ìŠµ ê³¼ì •
<ul id="cc2740a2-31c1-43a8-ad0a-1b28790f1a26" class="bulleted-list"><li style="list-style-type:disc">í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜(ë˜ëŠ” ê°€ì¤‘ì¹˜(weight))ë¥¼ ê°–ëŠ” ì‹ ê²½ë§ ì •ì˜</li></ul><ul id="d93021b7-7aca-41de-adb3-e5c780068e0b" class="bulleted-list"><li style="list-style-type:disc">ë°ì´í„°ì…‹(dataset) ì…ë ¥ì„ ë°˜ë³µ</li></ul><ul id="4aa1804f-1c0e-41c0-86dc-7d5a9343bd8b" class="bulleted-list"><li style="list-style-type:disc">ì…ë ¥ì„ ì‹ ê²½ë§ì—ì„œ ì „íŒŒ(process)</li></ul><ul id="456bf1b0-4adc-4cce-89f9-50a321740a93" class="bulleted-list"><li style="list-style-type:disc">ì†ì‹¤(loss; ì¶œë ¥ì´ ì •ë‹µìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€)ì„ ê³„ì‚°</li></ul><ul id="a9f2c518-6623-4ca0-8702-084c4c5905d9" class="bulleted-list"><li style="list-style-type:disc">ë³€í™”ë„(gradient)ë¥¼ ì‹ ê²½ë§ì˜ ë§¤ê°œë³€ìˆ˜ë“¤ì— ì—­ìœ¼ë¡œ ì „íŒŒ</li></ul><ul id="8a715a29-c37d-4dfe-a1d9-a86f15e5a524" class="bulleted-list"><li style="list-style-type:disc">ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê°„ë‹¨í•œ ê·œì¹™ì„ ì‚¬ìš©
<code>ìƒˆë¡œìš´Â ê°€ì¤‘ì¹˜(weight)Â =Â ê°€ì¤‘ì¹˜(weight)Â -Â í•™ìŠµë¥ (learningÂ rate)Â *Â ë³€í™”ë„(gradient)</code></li></ul></div></figure><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">ì‹ ê²½ë§ ì •ì˜</summary><div class="indented"><pre id="42992c26-d3a1-4d79-97ba-0dc9b3124349" class="code"><code>import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
	def __init__(self) :
		super(Net, self).__init__()
		#ì…ë ¥ ì´ë¯¸ì§€ ì±„ë„ 1ê°œ, ì¶œë ¥ ì±„ë„ 6ê°œ, 5x5ì˜ ì •ì‚¬ê° ì»¨ë³¼ë£¨ì…˜ í–‰ë ¬
		#ì»¨ë³¼ë£¨ì…˜ ì»¤ë„ ì •ì˜
		self.conv1 = nn.Conv2d (1,6,5)
		self.conv2 = nn.Conv2d(6,16,5)
		#ì•„í•€(affine) ì—°ì‚°: y = Wx + b
		self.fc1 = nn.Linear(16*5*5,120) #5*5ëŠ” ì´ë¯¸ì§€ ì°¨ì›ì— í•´ë‹¹
		self.fc2 = nn.Linear(120,84)
		self.fc3 = nn.Linear(84, 10)

	def forward(self, x) :
		# (2,2) í¬ê¸° ìœˆë„ìš°ì— ëŒ€í•´ ë§¥ìŠ¤ í’€ë§(Max Pooling)
		x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))
		# í¬ê¸°ê°€ ì œê³±ìˆ˜ë¼ë©´, í•˜ë‚˜ì˜ ìˆ«ìë§Œì„ íŠ¹ì •(specify)
		x = F.max_pool2d(F.relu(self.conv2(x)), 2)
    x = torch.flatten(x, 1) # ë°°ì¹˜ ì°¨ì›ì„ ì œì™¸í•œ ëª¨ë“  ì°¨ì›ì„ í•˜ë‚˜ë¡œ í‰íƒ„í™”(flatten)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return x


net = Net()
print(net)</code></pre><p id="82ef04e4-0382-40dd-87a0-7e68728e2177" class=""><code>forward</code><strong>Â í•¨ìˆ˜ë§Œ ì •ì˜í•˜ê³  ë‚˜ë©´, (ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ëŠ”)Â </strong><code>backward</code><strong>Â í•¨ìˆ˜ëŠ”Â </strong><code>autograd</code><strong>Â ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ì •ì˜</strong></p><p id="a6c41b06-e9e5-43ce-9b2f-a29d10bf4d5d" class=""><strong>ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì€Â </strong><code><strong>net.parameters()</strong></code><strong>Â ì— ì˜í•´ ë°˜í™˜ë©ë‹ˆë‹¤.</strong></p><pre id="0ce505b9-9438-4322-b6ea-d3f564bf1fe1" class="code"><code>params = list(net.parameters())
print(len(params)
print(params[0].size())    # conv1ì˜ .weight</code></pre><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="059aa6d3-d5c9-4fca-a051-f3842bbad4e1"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%"><strong>Note: ì´ ì‹ ê²½ë§(LeNet)ì˜ ì˜ˆìƒë˜ëŠ” ì…ë ¥ í¬ê¸°ëŠ” 32x32
ì´ ì‹ ê²½ë§ì— MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”,
ë°ì´í„°ì…‹ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 32x32ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤</strong></div></figure><pre id="ab0a2be8-1e76-413f-a2d6-99cdd3f72126" class="code"><code>input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)</code></pre><p id="2be48d03-26fa-4d60-9f92-549a86486491" class=""><strong>ëª¨ë“  ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ ë²„í¼(gradient buffer)ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ í•©ë‹ˆë‹¤</strong></p><pre id="b95ef094-7bbb-48f9-897c-230f5e6725bb" class="code"><code>net.zero_grad()
out.backward(torch.randn(1, 10))</code></pre><p id="ec28c37b-1ff5-4f4e-8b4f-46d3cfa1a13a" class="">
</p></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">ì†ì‹¤ í•¨ìˆ˜ (loss function)</summary><div class="indented"><p id="e50a0f98-95e9-4fa4-92f6-7bfa6a923df5" class="">ì¶œë ¥(output) ë° ì •ë‹µ(target)ì„ í•œ ìŒìœ¼ë¡œ ì…ë ¥ë°›ì•„, ì¶œë ¥(output)ì´ ì •ë‹µ(target)ê³¼ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì¶”ì •í•˜ëŠ” ê°’ì„ ê³„ì‚°</p><ul id="6ccc24fd-7005-481c-97b8-dd7caecab8f6" class="bulleted-list"><li style="list-style-type:disc"><strong>nn íŒ¨í‚¤ì§€ì—ëŠ” ì—¬ëŸ¬ê°€ì§€ì˜Â </strong><a href="http://pytorch.org/docs/nn.html#loss-functions">ì†ì‹¤ í•¨ìˆ˜ë“¤</a><strong>Â ì´ ì¡´ì¬</strong></li></ul><pre id="f8a221b7-9809-42e8-96ac-7022be5e904a" class="code"><code># ì˜ˆì‹œ) í‰ê· ì œê³±ì˜¤ì°¨ (Mean-squared erro) - nn.MSEloss

output = net(input)
target = torch.randn(10)  # ì˜ˆì‹œë¥¼ ìœ„í•œ ì„ì˜ì˜ ì •ë‹µ
target = target.view(1, -1)  # ì¶œë ¥ê³¼ ê°™ì€ shapeë¡œ ë§Œë“¦
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)</code></pre><p id="2ca80be4-b08c-4123-92b3-64d69fe43bdc" class=""><code>.grad_fn</code><strong>Â ì†ì„±ì„ ì‚¬ìš©í•˜ì—¬Â </strong><code>loss</code><strong>Â ë¥¼ ì—­ë°©í–¥ì—ì„œ ë”°ë¼ê°€ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ë³´ê¸°</strong></p><blockquote id="71b2af31-e219-47a0-8c43-54d0abb60109" class="">inputâ†’conv2dâ†’reluâ†’maxpool2dâ†’conv2dâ†’reluâ†’maxpool2d
         â†’flattenâ†’linearâ†’reluâ†’linearâ†’reluâ†’linearâ†’MSELoss
         â†’loss</blockquote><p id="4c7f6c98-5a90-457d-adfc-3aca3914ffea" class="">
</p></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">ì—­ì „íŒŒ (back propagation)</summary><div class="indented"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="e1326c81-ddaa-410b-a72a-389d2851d1b7"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%"><strong>ì˜¤ì°¨(error)ë¥¼ ì—­ì „íŒŒí•˜ê¸° ìœ„í•´ì„œëŠ”Â </strong><strong><code>loss.backward()</code></strong><strong> ì‹¤ì‹œ</strong></div></figure><pre id="e59813fe-3b5f-4805-9264-688d09df5a8b" class="code"><code># ì—­ì „íŒŒ ì „ê³¼ í›„ì— conv1ì˜ bias ë³€ìˆ˜ì˜ ë³€í™”ë„ í™•ì¸
net.zero_grad()     # ëª¨ë“  ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ ë²„í¼ë¥¼ 0ìœ¼ë¡œ ë§Œë“¦

print(&#x27;conv1.bias.grad before backward&#x27;)
print(net.conv1.bias.grad)

loss.backward()

print(&#x27;conv1.bias.grad after backward&#x27;)
print(net.conv1.bias.grad)</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">ê°€ì¤‘ì¹˜ ê°±ì‹ </summary><div class="indented"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="b402ed9d-67ea-4c0b-b212-5790edba8efe"><div style="font-size:1.5em"><span class="icon">ğŸ’¡</span></div><div style="width:100%"><code>optimizer.zero_grad()</code><strong>Â ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ë³€í™”ë„ ë²„í¼ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì— ìœ ì˜</strong></div></figure><ul id="4ffb31d7-076c-4d06-a310-45b4536db6e4" class="bulleted-list"><li style="list-style-type:disc">ê°€ì¥ ë‹¨ìˆœí•œ ê°±ì‹ ê·œì¹™ : í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• (SGD: Stochastic Gradient Descent)<ul id="2c97d5f1-af99-474b-bb2b-6e67dbd2ac33" class="bulleted-list"><li style="list-style-type:circle"><code><strong>ìƒˆë¡œìš´Â ê°€ì¤‘ì¹˜(weight)Â =Â ê°€ì¤‘ì¹˜(weight)Â -Â í•™ìŠµë¥ (learningÂ rate)Â *Â ë³€í™”ë„(gradient)</strong></code></li></ul><pre id="8ea84394-f3bd-414e-81c8-937d68f44451" class="code"><code>learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)</code></pre></li></ul><ul id="6f743fdd-c817-4c51-9c2e-685bdf6e63c7" class="bulleted-list"><li style="list-style-type:disc">torch.optimì— SGD, Nesterov-SGD, Adam, RMSProp ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê°±ì‹  ê·œì¹™ ìˆìŒ</li></ul><pre id="07ca545f-9ef9-4378-939f-a701c2b25cda" class="code"><code>import torch.optim as optim

# Optimizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
optimizer = optim.SGD(net.parameters(), lr=0.01)

# í•™ìŠµ ê³¼ì •(training loop)ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
optimizer.zero_grad()   # ë³€í™”ë„ ë²„í¼ë¥¼ 0ìœ¼ë¡œ
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()    # ì—…ë°ì´íŠ¸ ì§„í–‰</code></pre></div></details></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3">Classifier í•™ìŠµí•˜ê¸°</summary><div class="indented"><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3">ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°</summary><div class="indented"><p id="a1fc423a-4f46-443b-8dda-82b9e882ec1d" class=""><strong>ì¼ë°˜ì ìœ¼ë¡œ ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ë‚˜ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•ŒëŠ” í‘œì¤€ Python íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ NumPy ë°°ì—´ë¡œ ë¶ˆëŸ¬ì˜¤ë©´ ë©ë‹ˆë‹¤. ê·¸ í›„ ë°°ì—´ì„Â </strong><code><strong>torch.*Tensor</strong></code><strong>Â ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.</strong></p><p id="91115e47-9dd7-4f2a-8b58-163e797ea6fb" class="">
</p><ul id="03b56e34-3c9d-4c37-90e7-99b5dcbf9324" class="bulleted-list"><li style="list-style-type:disc"><strong>ì´ë¯¸ì§€ëŠ” Pillowë‚˜ OpenCV ê°™ì€ íŒ¨í‚¤ì§€ê°€ ìœ ìš©í•©ë‹ˆë‹¤.</strong></li></ul><ul id="af1b2035-38ad-4e7e-8d3b-27992fc090bc" class="bulleted-list"><li style="list-style-type:disc"><strong>ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” SciPyì™€ LibROSAê°€ ìœ ìš©í•˜ê³ ìš”.</strong></li></ul><ul id="4148a06f-0a66-4a1c-a89d-a9f163544684" class="bulleted-list"><li style="list-style-type:disc"><strong>í…ìŠ¤íŠ¸ì˜ ê²½ìš°ì—ëŠ” ê·¸ëƒ¥ Pythonì´ë‚˜ Cythonì„ ì‚¬ìš©í•´ë„ ë˜ê³ , NLTKë‚˜ SpaCyë„ ìœ ìš©í•©ë‹ˆë‹¤.</strong></li></ul></div></details><details open=""><summary style="font-weight:600;font-size:1.5em;line-height:1.3">cifar10  í•™ìŠµí•˜ê¸°</summary><div class="indented"><blockquote id="4ee93541-6dd7-419e-ac63-3d7423700720" class=""><strong>ì§„í–‰ ìˆœì„œ</strong><ol type="1" id="9148e699-23c3-4646-addd-d24fe50b185d" class="numbered-list" start="1"><li><code><strong>torchvision</strong></code><strong>Â ì„ ì‚¬ìš©í•˜ì—¬ CIFAR10ì˜ í•™ìŠµìš© / ì‹œí—˜ìš© ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , ì •ê·œí™”(nomarlizing)í•©ë‹ˆë‹¤.</strong></li></ol><ol type="1" id="0d037352-fb63-4021-804f-487e03a0f34b" class="numbered-list" start="2"><li><strong>í•©ì„±ê³± ì‹ ê²½ë§(Convolution Neural Network)ì„ ì •ì˜í•©ë‹ˆë‹¤.</strong></li></ol><ol type="1" id="a83a5738-057f-4e94-9099-f760a5aa0073" class="numbered-list" start="3"><li><strong>ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.</strong></li></ol><ol type="1" id="1c277850-ea56-411c-8925-90f6b2928d61" class="numbered-list" start="4"><li><strong>í•™ìŠµìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤.</strong></li></ol><ol type="1" id="c31f580a-1dd4-4c3c-9d84-405da7fb4ab3" class="numbered-list" start="5"><li><strong>ì‹œí—˜ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.</strong></li></ol></blockquote><pre id="10cae0d0-eef2-4de8-8797-931edfcb93ef" class="code"><code># No.1 : import dataset &amp; nomarlizing
import torch
import torchvision
import torchvision.transforms as transforms

# torchvision ë°ì´í„°ì…‹ì˜ ì¶œë ¥(output)ì€ [0, 1] ë²”ìœ„ë¥¼ ê°–ëŠ” PILImage ì´ë¯¸ì§€
# ì´ë¥¼ [-1, 1]ì˜ ë²”ìœ„ë¡œ ì •ê·œí™”ëœ Tensorë¡œ ë³€í™˜
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;,
           &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)


# Image ì •ìƒì ìœ¼ë¡œ ë“¤ì–´ì™”ëŠ”ì§€ í™•ì¸í•˜ê¸°
import matplotlib.pyplot as plt
import numpy as np

# ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ í•¨ìˆ˜

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì˜¤ê¸°
dataiter = iter(trainloader)
images, labels = next(dataiter)

# ì´ë¯¸ì§€ ë³´ì—¬ì£¼ê¸°
imshow(torchvision.utils.make_grid(images))
# ì •ë‹µ(label) ì¶œë ¥
print(&#x27; &#x27;.join(f&#x27;{classes[labels[j]]:5s}&#x27; for j in range(batch_size)))


# No.2 : í•©ì„±ê³±(CNN) ì •ì˜í•˜ê¸°
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # ë°°ì¹˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ì°¨ì›ì„ í‰íƒ„í™”(flatten)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()


# No.3 : ì†ì‹¤í•¨ìˆ˜ì™€ Optimizer ì •ì˜
# êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤(Cross-Entropy loss)ê³¼ ëª¨ë©˜í…€(momentum) ê°’ì„ ê°–ëŠ” SGDë¥¼ ì‚¬ìš©.
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)


# No.4 : ì‹ ê²½ë§ í•™ìŠµí•˜ê¸°
# ë°ì´í„°ë¥¼ ë°˜ë³µí•´ì„œ ì‹ ê²½ë§ì— ì…ë ¥ìœ¼ë¡œ ì œê³µí•˜ê³ , ìµœì í™”(Optimize) ì§„í–‰
for epoch in range(2):   # ë°ì´í„°ì…‹ì„ ìˆ˜ì°¨ë¡€ ë°˜ë³µí•©ë‹ˆë‹¤.

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # [inputs, labels]ì˜ ëª©ë¡ì¸ dataë¡œë¶€í„° ì…ë ¥ì„ ë°›ì€ í›„;
        inputs, labels = data

        # ë³€í™”ë„(Gradient) ë§¤ê°œë³€ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ê³ 
        optimizer.zero_grad()

        # ìˆœì „íŒŒ + ì—­ì „íŒŒ + ìµœì í™”ë¥¼ í•œ í›„
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f&#x27;[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}&#x27;)
            running_loss = 0.0

print(&#x27;Finished Training&#x27;)


# í•™ìŠµí•œ ëª¨ë¸ì„ ì €ì¥
# ìì„¸í•œ ì €ì¥ ë°©ë²• : https://pytorch.org/docs/stable/notes/serialization.html
PATH = &#x27;./cifar_net.pth&#x27;
torch.save(net.state_dict(), PATH)


# No.5 : Test ë¡œ ê²€ì¦í•˜ê¸°
# 1. test data í™•ì¸
dataiter = iter(testloader)
images, labels = next(dataiter)

# ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
imshow(torchvision.utils.make_grid(images))
print(&#x27;GroundTruth: &#x27;, &#x27; &#x27;.join(f&#x27;{classes[labels[j]]:5s}&#x27; for j in range(4)))

# ì €ì¥í–ˆë˜ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸°
net = Net()
net.load_state_dict(torch.load(PATH))

# Test ì‹¤ì‹œ
outputs = net(images)
# ì–´ë–¤ ë¶„ë¥˜ì— ëŒ€í•´ì„œ ë” ë†’ì€ ê°’ì´ ë‚˜íƒ€ë‚œë‹¤ëŠ” ê²ƒì€,
# ì‹ ê²½ë§ì´ ê·¸ ì´ë¯¸ì§€ê°€ í•´ë‹¹ ë¶„ë¥˜ì— ë” ê°€ê¹ë‹¤ê³  ìƒê°í•œë‹¤ëŠ” ê²ƒ
_, predicted = torch.max(outputs, 1)

print(&#x27;Predicted: &#x27;, &#x27; &#x27;.join(f&#x27;{classes[predicted[j]]:5s}&#x27;
                              for j in range(4)))

# ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œëŠ” ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
correct = 0
total = 0
# í•™ìŠµ ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ, ì¶œë ¥ì— ëŒ€í•œ ë³€í™”ë„ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤
with torch.no_grad():
    for data in testloader:
        images, labels = data
        # ì‹ ê²½ë§ì— ì´ë¯¸ì§€ë¥¼ í†µê³¼ì‹œì¼œ ì¶œë ¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤
        outputs = net(images)
        # ê°€ì¥ ë†’ì€ ê°’(energy)ë¥¼ ê°–ëŠ” ë¶„ë¥˜(class)ë¥¼ ì •ë‹µìœ¼ë¡œ ì„ íƒí•˜ê² ìŠµë‹ˆë‹¤
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f&#x27;Accuracy of the network on the 10000 test images: {100 * correct // total} %&#x27;)


#ì˜ ë¶„ë¥˜í•œê²ƒê³¼ ëª»í•œê²ƒ í™•ì¸ ì ˆì°¨
# ê° ë¶„ë¥˜(class)ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ê³„ì‚°ì„ ìœ„í•´ ì¤€ë¹„
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

# ë³€í™”ë„ëŠ” ì—¬ì „íˆ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predictions = torch.max(outputs, 1)
        # ê° ë¶„ë¥˜ë³„ë¡œ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ ìˆ˜ë¥¼ ëª¨ìë‹ˆë‹¤
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1


# ê° ë¶„ë¥˜ë³„ ì •í™•ë„(accuracy)ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f&#x27;Accuracy for class: {classname:5s} is {accuracy:.1f} %&#x27;)</code></pre><h3 id="401bdbb6-8b8c-441e-a710-4db107ec7677" class="">GPUì—ì„œ í•™ìŠµí•˜ê¸°</h3><pre id="61ffdf8b-d12c-46fe-8828-10b1faa7828c" class="code"><code>device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)
# CUDA ê¸°ê¸°ê°€ ì¡´ì¬í•œë‹¤ë©´, ì•„ë˜ ì½”ë“œê°€ CUDA ì¥ì¹˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤:
print(device)


# ë©”ì†Œë“œ(Method)ë“¤ì€ ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  ëª¨ë“ˆì˜ ë§¤ê°œë³€ìˆ˜ì™€ ë²„í¼ë¥¼ CUDA tensorë¡œ ë³€ê²½
net.to(device)

# ê° ë‹¨ê³„ì—ì„œ ì…ë ¥(input)ê³¼ ì •ë‹µ(target)ë„ GPë¡œ ì „ì†¡
inputs, labels = data[0].to(device), data[1].to(device)</code></pre><p id="49e94787-07cb-480d-8653-0c9461be7e94" class="">ëª¨ë“  GPUë¥¼ í™œìš©í•´ì„œ ë”ìš± ë” ì†ë„ë¥¼ ì˜¬ë¦¬ê³  ì‹¶ë‹¤ë©´,Â 
<a href="https://tutorials.pytorch.kr/beginner/blitz/data_parallel_tutorial.html">ì„ íƒ ì‚¬í•­: ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ (Data Parallelism)</a>Â ì„ ì°¸ê³  í•  ê²ƒ</p><p id="a3b733fc-1800-4735-adf7-e514372127b7" class="">
</p></div></details></div></details></div></article></body></html>